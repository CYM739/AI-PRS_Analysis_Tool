# src/views_edu/library_view_edu.py
import streamlit as st
import pandas as pd
import pickle
import base64
from logic.data_processing import analyze_csv, run_analysis, expand_terms
from utils.state_management import reset_state, initialize_session_state
from views.library_view import load_library, save_library # ç›´æ¥æ²¿ç”¨å°ˆæ¥­ç‰ˆçš„å‡½å¼

def render():
    """æ¸²æŸ“å°ˆæ¡ˆè³‡æ–™åº«ä»‹é¢ (æ•™è‚²ç‰ˆ) çš„æ‰€æœ‰ UI å…ƒä»¶èˆ‡é‚è¼¯ã€‚"""
    st.header("å°ˆæ¡ˆè³‡æ–™åº«èˆ‡æ¨¡å‹åˆ†æ")
    st.info("æ­¡è¿ä½¿ç”¨ AIPRS æ•™è‚²ç‰ˆï¼è«‹ä¾ç…§ä»¥ä¸‹æ­¥é©Ÿä¾†å®Œæˆæ‚¨çš„åˆ†æã€‚")

    # --- æ­¥é©Ÿä¸€ï¼šå»ºç«‹æ–°å°ˆæ¡ˆ ---
    with st.container(border=True):
        st.subheader("ç¬¬ä¸€æ­¥ï¼šä¸Šå‚³è³‡æ–™ä¸¦å»ºç«‹å°ˆæ¡ˆ")
        st.markdown("è«‹ä¸Šå‚³æ‚¨çš„ CSV æ ¼å¼å¯¦é©—æ•¸æ“šã€‚æª”æ¡ˆä¸­æ‡‰åŒ…å«æ•¸å€‹ä»£è¡¨**è®Šå› **çš„æ¬„ä½ï¼Œä»¥åŠä¸€å€‹æˆ–å¤šå€‹ä»£è¡¨**çµæœ**çš„æ¬„ä½ã€‚")

        uploaded_file = st.file_uploader("é»æ“Šæ­¤è™•ä¸Šå‚³æ‚¨çš„ CSV æª”æ¡ˆ", type=["csv"])
        project_name_input = st.text_input("è«‹ç‚ºæ‚¨çš„å°ˆæ¡ˆå‘½å", "æˆ‘çš„æ•™å­¸åˆ†æå°ˆæ¡ˆ")

        if st.button("å»ºç«‹æ–°å°ˆæ¡ˆ", type="primary"):
            if uploaded_file is not None and project_name_input:
                library = load_library()
                if project_name_input in library:
                    st.error(f"åç‚º '{project_name_input}' çš„å°ˆæ¡ˆå·²å­˜åœ¨ï¼Œè«‹æ›ä¸€å€‹åç¨±ã€‚")
                else:
                    try:
                        # å„ªå…ˆå˜—è©¦ UTF-8
                        df = pd.read_csv(uploaded_file, encoding='utf-8')
                    except UnicodeDecodeError:
                        # è‹¥å¤±æ•—ï¼Œå‰‡å˜—è©¦ Big5 (ms950)
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding='ms950')

                    (data_df, _, independent_vars, dependent_vars,
                     _, _, _, _, _) = analyze_csv(df)

                    if not dependent_vars or not independent_vars:
                        st.error("è³‡æ–™é©—è­‰å¤±æ•—ï¼šè«‹ç¢ºèªæ‚¨çš„ CSV æª”æ¡ˆä¸­åŒ…å«ç¬¦åˆå‘½åè¦å‰‡çš„è®Šå› èˆ‡çµæœæ¬„ä½ã€‚")
                        st.stop()
                    
                    df_json = df.to_json(orient='split')
                    library[project_name_input] = {
                        "data_df_json": df_json,
                        "analysis_runs": {}
                    }
                    save_library(library)
                    st.success(f"æˆåŠŸå»ºç«‹å°ˆæ¡ˆ '{project_name_input}'ï¼å·²è‡ªå‹•ç‚ºæ‚¨è¼‰å…¥è³‡æ–™ã€‚")
                    
                    reset_state()
                    (st.session_state.exp_df, st.session_state.all_vars, st.session_state.independent_vars,
                     st.session_state.dependent_vars, st.session_state.variable_stats,
                     _, st.session_state.unique_variable_values,
                     st.session_state.variable_descriptions,
                     st.session_state.detected_binary_vars) = analyze_csv(df)
                    st.session_state.processed_file = project_name_input
                    st.rerun()
            else:
                st.warning("è«‹å‹™å¿…ä¸Šå‚³æª”æ¡ˆä¸¦ç‚ºå°ˆæ¡ˆå‘½åã€‚")

    st.divider()

    # --- æ–°å¢çš„å°ˆæ¡ˆç®¡ç†å€å¡Š ---
    library = load_library()
    if library: # åªæœ‰ç•¶è³‡æ–™åº«ä¸­æœ‰å°ˆæ¡ˆæ™‚æ‰é¡¯ç¤º
        with st.container(border=True):
            st.subheader("å°ˆæ¡ˆç®¡ç† (è¼‰å…¥èˆ‡åˆªé™¤)")
            
            projects = sorted(list(library.keys()))
            selected_project = st.selectbox("é¸æ“‡ä¸€å€‹å·²å­˜åœ¨çš„å°ˆæ¡ˆ", projects)

            col1, col2 = st.columns(2)
            with col1:
                if st.button("è¼‰å…¥é¸å®šå°ˆæ¡ˆ", use_container_width=True):
                    project_data = library[selected_project]
                    df_json = project_data['data_df_json']
                    df = pd.read_json(df_json, orient='split')

                    reset_state()
                    (st.session_state.exp_df, st.session_state.all_vars, st.session_state.independent_vars,
                     st.session_state.dependent_vars, st.session_state.variable_stats,
                     _, st.session_state.unique_variable_values,
                     st.session_state.variable_descriptions,
                     st.session_state.detected_binary_vars) = analyze_csv(df)
                    st.session_state.processed_file = selected_project
                    st.success(f"å·²æˆåŠŸè¼‰å…¥å°ˆæ¡ˆ '{selected_project}'ã€‚")
                    st.rerun()
            
            with col2:
                if st.button("åˆªé™¤é¸å®šå°ˆæ¡ˆ", type="secondary", use_container_width=True):
                    if selected_project in library:
                        del library[selected_project]
                        save_library(library)
                    if st.session_state.get('processed_file') == selected_project:
                        reset_state()
                    st.success(f"å·²åˆªé™¤å°ˆæ¡ˆ '{selected_project}'")
                    st.rerun()

    # --- æ­¥é©ŸäºŒï¼šåŸ·è¡Œåˆ†æ ---
    if st.session_state.get('processed_file'):
        with st.container(border=True):
            st.subheader(f"ç¬¬äºŒæ­¥ï¼šç‚ºå°ˆæ¡ˆã€Œ{st.session_state.processed_file}ã€åŸ·è¡Œæ¨¡å‹åˆ†æ")
            st.info("æ•™è‚²ç‰ˆé è¨­ä½¿ç”¨ã€Œå¤šé …å¼ OLS (Ordinary Least Squares)ã€æ¨¡å‹ã€‚é€™æ˜¯ä¸€ç¨®çµ±è¨ˆå­¸æ–¹æ³•ï¼Œç”¨æ–¼å»ºç«‹è®Šå› èˆ‡çµæœä¹‹é–“çš„æ•¸å­¸æ–¹ç¨‹å¼ï¼Œæ˜¯åæ‡‰æ›²é¢åˆ†æçš„åŸºç¤ã€‚")

            analysis_name = "é è¨­ OLS åˆ†æ"
            st.markdown(f"åˆ†æåç¨±å°‡è¨­å®šç‚ºï¼š **{analysis_name}**")

            if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œåˆ†æ", type="primary", use_container_width=True):
                project_data = library[st.session_state.processed_file]
                if analysis_name in project_data.get("analysis_runs", {}):
                    st.warning(f"åç‚º '{analysis_name}' çš„åˆ†æå·²å­˜åœ¨ã€‚çµæœå°‡è¢«è¦†è“‹ã€‚")

                with st.spinner("æ­£åœ¨å»ºç«‹æ•¸å­¸æ¨¡å‹ï¼Œè«‹ç¨å€™..."):
                    try:
                        df_for_analysis = st.session_state.exp_df.copy()
                        expand_terms(df_for_analysis, st.session_state.independent_vars)
                        st.session_state.expanded_df = df_for_analysis
                        
                        models_to_store = {}
                        current_wrapped_models = {}

                        for dep_var in st.session_state.dependent_vars:
                            clean_df = df_for_analysis.dropna(subset=[dep_var] + st.session_state.independent_vars).copy()
                            wrapped_model = run_analysis(
                                clean_df, st.session_state.independent_vars, dep_var, 'Polynomial OLS', {}
                            )
                            y_actual = clean_df[dep_var]
                            y_predicted = wrapped_model.predict(clean_df)
                            avp_df = pd.DataFrame({'Actual': y_actual, 'Predicted': y_predicted})
                            
                            current_wrapped_models[dep_var] = wrapped_model
                            pickled_model = pickle.dumps(wrapped_model)
                            b64_model = base64.b64encode(pickled_model).decode('utf-8')
                            
                            models_to_store[dep_var] = {
                                "model_wrapper_b64": b64_model,
                                "summary_text": wrapped_model.get_summary(),
                                "actual_vs_predicted_csv": avp_df.to_csv(index=False)
                            }
                        
                        library[st.session_state.processed_file]['analysis_runs'][analysis_name] = {
                            "model_type": 'Polynomial OLS',
                            "models": models_to_store
                        }
                        save_library(library)
                        
                        st.session_state.wrapped_models = current_wrapped_models
                        st.session_state.analysis_done = True
                        st.session_state.active_analysis_run = analysis_name
                        st.success("æ¨¡å‹åˆ†æå®Œæˆï¼æ‚¨ç¾åœ¨å¯ä»¥å‰å¾€ã€Œåœ–è¡¨è¦–è¦ºåŒ–ã€èˆ‡ã€ŒAI æ™ºæ…§å„ªåŒ–ã€åˆ†é æ¢ç´¢çµæœã€‚")
                        st.rerun()

                    except Exception as e:
                        st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")